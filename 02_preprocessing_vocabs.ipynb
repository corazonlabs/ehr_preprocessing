{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp preprocessing.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from lemonade.preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dfs = load_ehr_vocabcodes(PATH_1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_codes, obs_codes, alg_codes, crpl_codes, med_codes, img_codes, proc_codes, cnd_codes, immn_codes = code_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EhrVocab():\n",
    "    def __init__(self, itoc, ctoi, ctod=None):\n",
    "        self.itoc = itoc\n",
    "        self.ctoi = ctoi\n",
    "        if ctod is not None: self.ctod = ctod \n",
    "        self.vocab_size = len(self.itoc)\n",
    "        \n",
    "    @classmethod\n",
    "    def create(cls, codes_df):\n",
    "        desc_exists = 'desc' in codes_df.columns\n",
    "        codes_df = codes_df.astype({'code':'str'})\n",
    "        itoc = list(codes_df.code.unique())  #old --> list(set(codes_df.code))\n",
    "        itoc.insert(0,'xxnone')\n",
    "        itoc.insert(1,'xxunk')\n",
    "        \n",
    "        ctoi = {code: i for i, code in enumerate(itoc)}\n",
    "        \n",
    "        if desc_exists:\n",
    "            codes_df.set_index('code', inplace=True)\n",
    "            ctod = {}\n",
    "            ctod[itoc[0]] = \"Nothing recorded\"\n",
    "            ctod[itoc[1]] = \"Unknown\"\n",
    "            for code in itoc[2:]: \n",
    "                ctod[code] = set(codes_df.loc[code].desc)\n",
    "        \n",
    "        return cls(itoc, ctoi, ctod) if desc_exists else cls(itoc, ctoi)\n",
    "    \n",
    "    def get_emb_dims(self, αd=0.5736):\n",
    "        return self.vocab_size, round(6* αd * (self.vocab_size**0.25))\n",
    "    \n",
    "    def numericalize(self, codes, verbose=True):\n",
    "        today = date.today().strftime(\"%Y-%m-%d\")\n",
    "        logfile = f'./log/{today}_numericalize_exceptions.log'\n",
    "        \n",
    "        res = []\n",
    "        try:\n",
    "            res = [self.ctoi[str(code)] for code in codes] #no big performance benefit\n",
    "        except KeyError:\n",
    "            for code in codes:\n",
    "                try:\n",
    "                    res.append(self.ctoi[str(code)])\n",
    "                except KeyError:\n",
    "                    res.append(self.ctoi['xxunk'])\n",
    "                    if verbose:\n",
    "                        with open(logfile, 'a') as log:\n",
    "                            log.write(f'\\ncode: {code}')                      \n",
    "                    \n",
    "        return res\n",
    "    \n",
    "    def textify(self, indxs):\n",
    "        if hasattr(self, 'ctod'):\n",
    "            res = [ (self.itoc[i], self.ctod[self.itoc[i]]) for i in indxs ]\n",
    "        else:\n",
    "            res = [ (self.itoc[i]) for i in indxs ]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class `ObsVocab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObsVocab (EhrVocab):\n",
    "    def __init__(self, vocab_df):\n",
    "        self.vocab_df = vocab_df\n",
    "        self.vocab_size = len(vocab_df)\n",
    "    \n",
    "    def numericalize(self, codes, verbose=True):\n",
    "        today = date.today().strftime(\"%Y-%m-%d\")\n",
    "        logfile = f'./log/{today}_numericalize_exceptions.log'\n",
    "        \n",
    "        indxs = []\n",
    "        for code in codes:\n",
    "            if code in ['xxnone','xxunk']: indxs.extend(self.vocab_df[(self.vocab_df['code'] == code)].index.tolist())\n",
    "            else: \n",
    "                c,v,u,t = code.split('||')\n",
    "                if t == 'numeric':\n",
    "                    filt_df = self.vocab_df[(self.vocab_df['code'] == c) & (self.vocab_df['units'] == u) & (self.vocab_df['type'] == t)]\n",
    "                    res = filt_df.iloc[(filt_df.value - float(v)).abs().argsort()[:1]].index.tolist()\n",
    "                else:\n",
    "                    res = self.vocab_df[(self.vocab_df['code'] == c) & (self.vocab_df['value'] == v) & \\\n",
    "                                               (self.vocab_df['units'] == u) & (self.vocab_df['type'] == t)].index.tolist()\n",
    "                if len(res) == 0: \n",
    "                    indxs.extend(self.vocab_df[(self.vocab_df['code'] == 'xxunk')].index.tolist())\n",
    "                    if verbose:\n",
    "                        with open(logfile, 'a') as log:\n",
    "                            log.write(f'\\ncode in ObsVocab: {code}')                    \n",
    "                else            : indxs.extend(res)\n",
    "        assert len(codes) == len(indxs), \"Possible bug, not all codes being numericalized\"\n",
    "        return indxs\n",
    "    \n",
    "    def textify(self, indxs):\n",
    "        txts = []\n",
    "        for i in indxs:\n",
    "            c,d,v,u,t = self.vocab_df.iloc[i]\n",
    "            if i == 0: txts.append((c, d))\n",
    "            else:      txts.append((f'{c}||{v}||{u}||{t}', d))\n",
    "        assert len(indxs) == len(txts), \"Possible bug, not all indxs being textified\"\n",
    "        return txts\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, obs_codes, num_buckets=5):\n",
    "        numerics = pd.DataFrame(obs_codes.loc[obs_codes['type'] == 'numeric',:])\n",
    "        texts = pd.DataFrame(obs_codes.loc[obs_codes['type'] == 'text',:])\n",
    "        numerics = numerics.astype({'value':'float'}, copy=False)\n",
    "        vocab_rows = []\n",
    "\n",
    "        for code in numerics.orig_code.unique():\n",
    "            this_code = numerics.loc[numerics['orig_code'] == code]\n",
    "            for unit in this_code.units.unique():\n",
    "                this_unit = this_code.loc[this_code['units'] == unit]\n",
    "                for val in np.linspace(this_unit.value.min(), this_unit.value.max(), num=num_buckets):\n",
    "                    vocab_rows.append([code,this_unit.desc.iloc[0],val,unit,'numeric'])\n",
    "\n",
    "        for code in texts.orig_code.unique():\n",
    "            this_code = texts.loc[texts['orig_code'] == code]\n",
    "            for unit in this_code.units.unique():\n",
    "                this_unit = this_code.loc[this_code['units'] == unit]\n",
    "                for val in this_unit.value.unique():\n",
    "                    vocab_rows.append([code,this_unit.desc.iloc[0],val,unit,'text'])\n",
    "\n",
    "        vocab_rows.insert(0, ['xxnone','Nothing recorded','xxnone','xxnone','xxnone'])\n",
    "        vocab_rows.insert(1, ['xxunk','Unknown','xxunk','xxunk','xxunk'])\n",
    "        obs_vocab = pd.DataFrame(data=vocab_rows, columns=['code','desc','value','units','type'])\n",
    "        assert obs_codes.orig_code.nunique() == obs_vocab.code.nunique()-2, \"Possible bug, obs_code nuniques don't match\"\n",
    "        return cls(obs_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`numericalize()` Explanation**\n",
    "- split incoming concated `code||value||units||type` string\n",
    "- get a result_df based on everything except value\n",
    "- then do an `argsort()` on the value column to determine closest value\n",
    " - based on example given in [pandas docs - cookbook](https://pandas.pydata.org/docs/user_guide/cookbook.html#building-criteria)\n",
    "   - **cookbook example that uses `loc` doesnt work, instead `iloc` [works](https://stackoverflow.com/questions/30112202/how-do-i-find-the-closest-values-in-a-pandas-series-to-an-input-number/53553226)**\n",
    " - `argsort()` - [Returns the indices that would sort this array](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html#numpy.argsort)\n",
    " - `[:1]` on that returns the one row with the closest match, index of that is what we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VocabList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EhrVocabList:\n",
    "    def __init__(self, demographics_vocabs, records_vocabs, age_mean, age_std, path):\n",
    "        self.demographics_vocabs, self.records_vocabs, self.path = demographics_vocabs, records_vocabs, path\n",
    "        self.age_mean, self.age_std = age_mean, age_std\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, path, num_buckets=5):\n",
    "        demographics_vocabs, records_vocabs = [], []\n",
    "        code_dfs = load_ehr_vocabcodes(path)\n",
    "        \n",
    "        def _get_demographics_codes(pt_codes):\n",
    "            code_dfs = []\n",
    "            code_dfs.extend([pd.DataFrame(range(1, 32, 1), columns=['code'])]) #31 days  \n",
    "            code_dfs.extend([pd.DataFrame(range(1, 13, 1), columns=['code'])]) #12 months \n",
    "            code_dfs.extend([pd.DataFrame(range(1900, pd.Timestamp.today().year + 1, 1), columns=['code'])]) #years 1900 to now\n",
    "            code_dfs.extend([pd.DataFrame(pt_codes.marital.dropna().unique(), columns=['code'])])\n",
    "            code_dfs.extend([pd.DataFrame(pt_codes.race.dropna().unique(), columns=['code'])])\n",
    "            code_dfs.extend([pd.DataFrame(pt_codes.ethnicity.dropna().unique(), columns=['code'])])\n",
    "            code_dfs.extend([pd.DataFrame(pt_codes.gender.dropna().unique(), columns=['code'])])\n",
    "            code_dfs.extend([pd.DataFrame(pt_codes.birthplace.dropna().unique(), columns=['code'])])\n",
    "            code_dfs.extend([pd.DataFrame(pt_codes.city.dropna().unique(), columns=['code'])])\n",
    "            code_dfs.extend([pd.DataFrame(pt_codes.state.dropna().unique(), columns=['code'])])\n",
    "            code_dfs.extend([pd.DataFrame(pt_codes.zip.dropna().unique(), columns=['code'])])\n",
    "            age_mean, age_std = pt_codes.age_now_days.mean(), pt_codes.age_now_days.std()\n",
    "            return code_dfs, age_mean, age_std\n",
    "        \n",
    "        demographics_codes, age_mean, age_std = _get_demographics_codes(code_dfs[0])\n",
    "        demographics_vocabs.extend([EhrVocab.create(codes_df) for codes_df in demographics_codes])\n",
    "        records_vocabs.extend([ObsVocab.create(code_dfs[1], num_buckets)])\n",
    "        records_vocabs.extend([EhrVocab.create(codes_df) for codes_df in code_dfs[2:]])\n",
    "        return cls(demographics_vocabs, records_vocabs, age_mean, age_std, path)    \n",
    "    \n",
    "    def save(self):\n",
    "        pckl_dir = Path(f'{self.path}/processed')\n",
    "        pckl_dir.mkdir(parents=True, exist_ok=True)\n",
    "        pckl_f = open(f'{pckl_dir}/vocabs.vocablist', 'wb')\n",
    "        pickle.dump(self, pckl_f)\n",
    "        pckl_f.close()\n",
    "        print(f'Saved vocab lists to {pckl_dir}')\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        infile = open(f'{path}/processed/vocabs.vocablist','rb')\n",
    "        ehrVocabList = pickle.load(infile)\n",
    "        infile.close()\n",
    "        return ehrVocabList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Embedding Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_all_emb_dims(EhrVocabList, αd=0.5736):\n",
    "    demographics_dims = [vocab.get_emb_dims(αd) for vocab in EhrVocabList.demographics_vocabs]\n",
    "    recs_dims          = [vocab.get_emb_dims(αd) for vocab in EhrVocabList.records_vocabs]\n",
    "    \n",
    "#     emb_dims_list = [vocab.get_emb_dims() for vocab in vocabs_list]\n",
    "    demographics_dims_width = recs_dims_width = 0\n",
    "    for emb_dim in demographics_dims:\n",
    "        demographics_dims_width += emb_dim[1]\n",
    "    for emb_dim in recs_dims:\n",
    "        recs_dims_width += emb_dim[1]\n",
    "        \n",
    "    return demographics_dims, recs_dims, demographics_dims_width, recs_dims_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_preprocessing_clean.ipynb.\n",
      "Converted 02_preprocessing_vocabs.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
